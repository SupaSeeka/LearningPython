{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook contains an excerpt from the [Python Data Science Handbook](http://shop.oreilly.com/product/0636920034919.do) by Jake VanderPlas; the content is available [on GitHub](https://github.com/jakevdp/PythonDataScienceHandbook).*\n",
    "\n",
    "*The text is released under the [CC-BY-NC-ND license](https://creativecommons.org/licenses/by-nc-nd/3.0/us/legalcode), and code is released under the [MIT license](https://opensource.org/licenses/MIT). If you find this content useful, please consider supporting the work by [buying the book](http://shop.oreilly.com/product/0636920034919.do)!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing and Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the process of developing code, there are often trade-offs you can make between various implementations.\n",
    "Early in developing your algorithm, it can be counterproductive to worry about such things, and we have not worried about it until now. As Donald Knuth famously quipped, \"We should forget about small efficiencies, say about 97% of the time: premature optimization is the root of all evil.\"\n",
    "\n",
    "But once you have your code working, it can be useful to dig into its efficiency a bit.\n",
    "Sometimes it's useful to check the execution time of a given command or set of commands; other times it's useful to dig into a multiline process and determine where the bottleneck lies in some complicated series of operations.\n",
    "IPython provides access to a wide array of functionality for this kind of timing and profiling of code.\n",
    "Here we'll discuss the following IPython magic commands:\n",
    "\n",
    "- ``%time``: Time the execution of a single statement\n",
    "- ``%timeit``: Time repeated execution of a single statement for more accuracy\n",
    "- ``%prun``: Run code with the profiler\n",
    "- ``%lprun``: Run code with the line-by-line profiler\n",
    "- ``%memit``: Measure the memory use of a single statement\n",
    "- ``%mprun``: Run code with the line-by-line memory profiler\n",
    "\n",
    "The last four commands are not bundled with IPython by default – you may need to install the ``line_profiler`` and ``memory_profiler`` modules to use these on your own installation. Note that these magic functions using the `%` symbol are available to us here in Jupyter because they are provided by IPython, but these will not work in regular Python environments. There are alternative ways to use these modules without using magic functions, but we will not cover those methods here. Unfortunately, as you will see later in this notebook, the memory_profiler module has fallen into a state of disrepair over the past couple of years and some of its functionality no longer works under Python 3.12.\n",
    "\n",
    "If you are using Anaconda on your own machine and need to install these packages it can be easily done from the Anaconda Navigator. If you open the Navigator, and click on *Environments* in the left hand menu you should be presented with a list of packages already installed. If you change the dropdown at the top to *Not Installed* and then search for any of the packages below you will be able to select the package you wish to install and hit the *Apply* button in the bottom right of the Navigator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing Code Snippets: ``%timeit`` and ``%time``\n",
    "\n",
    "We can use the ``%timeit`` line-magic and ``%%timeit`` cell-magic to time the repeated execution of snippets of code. We can place the `%timeit` command in front of any line of Python code to time how long it takes to run just that single line. We use the `%%timeit` command to time all of the code within a particular Jupyter cell. The code below may take a little while to run. So long as you can see the `In [*]` on the left hand side it should be doing something useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit sum(range(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that because this operation is so fast, ``%timeit`` automatically does a large number of repetitions. In this case you will likely get a result that looks like: `1.36 µs ± 1.18 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)`\n",
    "\n",
    "This might look a bit strange, so lets break it down. Apparently we did 7 runs, so we repeated the same test 7 times to calculate an average. Each of those runs consisted of 1000000 loops, so we repeated this line of code 1000000 times in each of our 7 runs. The runtime of 1.36 microseconds is the average runtime of those 7 runs divided by 1000000, meaning each run took about 1.36 seconds, and our 7 runs take around 10 seconds. If you compare this to your stopwatch you will see a similar figure.\n",
    "\n",
    "\n",
    "For slower commands, ``%timeit`` will automatically adjust and perform fewer repetitions. This time we will measure the time taken to run the entire cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "total = 0\n",
    "for i in range(1000):\n",
    "    for j in range(1000):\n",
    "        total += i * (-1) ** j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still likely did 7 runs in order to calculate an average, but on each of those runs we only ran the cell once, we didn't run it multiple times as in the previous example.\n",
    "\n",
    "Sometimes repeating an operation is not the best option.\n",
    "For example, if we have a list that we'd like to sort, we might be misled by a repeated operation.\n",
    "Sorting a pre-sorted list is much faster than sorting an unsorted list, so the repetition will skew the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "L = [random.random() for i in range(100000)]\n",
    "%timeit L.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this, the ``%time`` magic function may be a better choice. It also is a good choice for longer-running commands, when short, system-related delays are unlikely to affect the result.\n",
    "Let's time the sorting of an unsorted and a presorted list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "L = [random.random() for i in range(100000)]\n",
    "print(\"sorting an unsorted list:\")\n",
    "%time L.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sorting an already sorted list:\")\n",
    "%time L.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how much faster the presorted list is to sort, but notice also how much longer the timing takes with ``%time`` versus ``%timeit``, even for the presorted list!\n",
    "This is a result of the fact that ``%timeit`` does some clever things under the hood to prevent system calls from interfering with the timing.\n",
    "For example, it prevents cleanup of unused Python objects (known as *garbage collection*) which might otherwise affect the timing.\n",
    "For this reason, ``%timeit`` results are usually noticeably faster than ``%time`` results.\n",
    "\n",
    "For ``%time`` as with ``%timeit``, using the double-percent-sign cell magic syntax allows timing of multiline scripts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "total = 0\n",
    "for i in range(1000):\n",
    "    for j in range(1000):\n",
    "        total += i * (-1) ** j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information on ``%time`` and ``%timeit``, as well as their available options, use the IPython help functionality (i.e., type ``%time?`` in a new cell or at the IPython prompt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling Full Scripts: ``%prun``\n",
    "\n",
    "A program is made of many single statements, and sometimes timing these statements in context is more important than timing them on their own.\n",
    "Python contains a built-in code profiler (which you can read about in the Python documentation), but IPython offers a much more convenient way to use this profiler, in the form of the magic function ``%prun``.\n",
    "\n",
    "By way of example, we'll define a simple function that does some calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_of_lists(N):\n",
    "    total = 0\n",
    "    for i in range(5000):\n",
    "        L = [j ^ (j >> i) for j in range(N)]\n",
    "        total += sum(L)\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call ``%prun`` with a function call to see the profiled results. We also pass the parameter `-l 5` to limit the output to the 5 most time consuming calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%prun -l 5 sum_of_lists(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the notebook, the output is printed to the pager, and looks something like this:\n",
    "\n",
    "```\n",
    "5610 function calls (5597 primitive calls) in 1.284 seconds\n",
    "\n",
    "   Ordered by: internal time\n",
    "   List reduced from 170 to 5 due to restriction <5>\n",
    "\n",
    "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "        1    0.710    0.710    1.098    1.098 <string>:1(<module>)\n",
    "        1    0.297    0.297    0.307    0.307 1228561257.py:1(sum_of_lists)\n",
    "       14    0.166    0.012    0.172    0.012 socket.py:626(send)\n",
    "     5000    0.098    0.000    0.098    0.000 {built-in method builtins.sum}\n",
    "        1    0.005    0.005    0.005    0.005 {method 'execute' of 'sqlite3.Connection' objects}\n",
    "```\n",
    "\n",
    "The result is a table that indicates, in order of total time on each function call, where the execution is spending the most time. In my case, the bulk of execution time is in the list comprehension inside ``sum_of_lists``. On NCC you might see time allocated to some other functions related to Jupyterhub internal communication if the system is busy. \n",
    "From here, we could start thinking about what changes we might make to improve the performance in the algorithm.\n",
    "\n",
    "For more information on ``%prun``, as well as its available options, use the IPython help functionality (i.e., type ``%prun?``  in a new cell or at the IPython prompt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line-By-Line Profiling with ``%lprun``\n",
    "\n",
    "The function-by-function profiling of ``%prun`` is useful, but generally it's more convenient to have a line-by-line profile report.\n",
    "This is not built into Python or IPython, but there is a ``line_profiler`` package available for installation that can do this.\n",
    "If you are using your own Python install you may have to do a ``pip`` install:\n",
    "\n",
    "```\n",
    "$ pip install line_profiler\n",
    "```\n",
    "\n",
    "You can optionally do this in your notebook with the code block below. Note that you **DO NOT** need to run this if you are using NCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you can use IPython to load the ``line_profiler`` IPython extension, offered as part of this package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the ``%lprun`` command will do a line-by-line profiling of any function–in this case, we need to tell it explicitly which functions we're interested in profiling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f sum_of_lists sum_of_lists(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, the notebook sends the result to the pager, but it looks something like this:\n",
    "\n",
    "```\n",
    "Timer unit: 1e-09 s\n",
    "\n",
    "Total time: 0.299292 s\n",
    "File: /tmp/ipykernel_2968883/1228561257.py\n",
    "Function: sum_of_lists at line 1\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     1                                           def sum_of_lists(N):\n",
    "     2         1       2144.0   2144.0      0.0      total = 0\n",
    "     3      5001    1973361.0    394.6      0.7      for i in range(5000):\n",
    "     4    505000  290069397.0    574.4     96.9          L = [j ^ (j >> i) for j in range(N)]\n",
    "     5      5000    7245194.0   1449.0      2.4          total += sum(L)\n",
    "     6         1       2304.0   2304.0      0.0      return total\n",
    "```\n",
    "\n",
    "The information at the top gives us the key to reading the results: the time is reported in microseconds and we can see where the program is spending the most time.\n",
    "At this point, we may be able to use this information to modify aspects of the script and make it perform better for our desired use case.\n",
    "\n",
    "For more information on ``%lprun``, as well as its available options, use the IPython help functionality (i.e., type ``%lprun?`` in a new cell or at the IPython prompt)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling Memory Use: ``%memit`` and ``%mprun``\n",
    "\n",
    "Another aspect of profiling is the amount of memory an operation uses.\n",
    "This can be evaluated with another IPython extension, the ``memory_profiler``. Unfortunately however, this Python package has not been actively maintained for the past couple of years, and it appears that some of its functionality no longer works correctly under Python 3.12. I maintain the information here to provide an overview of how the functionality used to work, and hopefully someone will decide to update this package or an alternative will become available.\n",
    "As with the ``line_profiler``, we start by ``pip``-installing the extension:\n",
    "\n",
    "```\n",
    "$ pip install memory_profiler\n",
    "```\n",
    "You can optionally do this in your notebook with the code block below. Note that you **DO NOT** need to run this if you are using NCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use IPython to load the extension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory profiler extension contains two useful magic functions: the ``%memit`` magic (which offers a memory-measuring equivalent of ``%timeit``) and the ``%mprun`` function (which offers a memory-measuring equivalent of ``%lprun``).\n",
    "The ``%memit`` function can be used rather simply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%memit sum_of_lists(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this function uses about 70 MB of memory.\n",
    "\n",
    "For a line-by-line description of memory use, we can use the ``%mprun`` magic. This works slightly different, and requires that our function be defined outside of our notebook. If yuo want to see sensible results I also recommended that you restart the kernel first.\n",
    "We can use the `%%file` magic command to write our function out to a file and then make use of the memory profiler as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file mprun_demo.py\n",
    "def sum_of_lists(N):\n",
    "    total = 0\n",
    "    for i in range(5):\n",
    "        M = [j ^ (j >> i) for j in range(N)]\n",
    "        total += sum(M)\n",
    "        del M # remove reference to L\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mprun_demo import sum_of_lists\n",
    "%mprun -f sum_of_lists sum_of_lists(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice some unusual results with massive negative numbers, particularly if you increase the parameter, or just 0.0 memory increments throughout. It appears that there are now various issues with the `%mprun` magic function, as has been the case in the last few versions! If all were working well you would expect to see something more along the lines of:\n",
    "\n",
    "```\n",
    "Filename: ./mprun_demo.py\n",
    "\n",
    "Line #    Mem usage    Increment   Line Contents\n",
    "================================================\n",
    "     1     39.0 MiB      0.0 MiB   def sum_of_lists(N):\n",
    "     2     39.0 MiB      0.0 MiB       total = 0\n",
    "     3     46.5 MiB      7.5 MiB       for i in range(5):\n",
    "     4     71.9 MiB     25.4 MiB           L = [j ^ (j >> i) for j in range(N)]\n",
    "     5     71.9 MiB      0.0 MiB           total += sum(L)\n",
    "     6     46.5 MiB    -25.4 MiB           del L # remove reference to L\n",
    "     7     39.1 MiB     -7.4 MiB       return total\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
