{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timing with the timeit Module ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in Notebook 6.1 we can use the magic functions to learn the execution time of an entire cell of code. Let us quickly remind ourselves of how the `%%timeit` magic function is used. The function `f` used in the example below is not important - it is designed to just take some non-negligible time, we are simply demonstrating use of the `%%timeit` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "\n",
    "def f(x):\n",
    "    for i in range (1,x):\n",
    "        x += x % 991\n",
    "    return x\n",
    "\n",
    "f(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using timeit\n",
    "\n",
    "The `%%timeit` magic function is convenient, and very simple to use if we just want to gauge how long it takes to run a single function with a specific input. However, it may be more interesting to time our function across a range of inputs, and there is no straightforward way to do this with `%%timeit`. However, Python does provide us with the `timeit` module, which provides us with some useful funtions for profiling our code.\n",
    "\n",
    "As usual, we must import this module, and then we can use the functions it provides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the same function as we used above, which serves no specific purpose other than to take a reasonable amount of time to execute. We only need to define it once to use it in all of our examples in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    for i in range (1,x):\n",
    "        x += x % 991\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us use the `timeit()` function provided by the timeit module to see how long it takes to execute our function with an input of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit.timeit('f(10)', globals=globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we had to pass into the timeit function the name of our function and its input as a string. We will not worry about the `globals=globals()` parameter, we should just remember that we need it. Technically this causes the timing code to be executed within the current global namespace. \n",
    "\n",
    "The data returned is the wall clock time in seconds that was required to run our function 1,000,000 times. This is because the timeit function has a default argument called `number` which takes the value 1,000,000 unless we override it. \n",
    "One key reason for this is that the timeit function measures wall clock time and the data can sometimes be skewed by other processes running on your machine. Running the function a large number of times allows us to calculate the average runtime, which can help account for inconsistencies in the data.\n",
    "\n",
    "Now let us try overriding the `number` argument with the value 100,000. This is 10 times smaller than the default value, so the run time should be around 10 times faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit.timeit('f(10)', globals=globals(), number=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should remember to divide the runtime returned by the value of `number` if we want to learn how long a single execution of our function takes on average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From a statistical viewpoint, you might be interested in more of the underlying data associated with multiple executions of your function. One way to achieve this is to use the `repeat()` function instead of the `timeit()` function. We can then provide a `repeat` parameter as follows:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeit.repeat('f(10)', globals=globals(), number=100000, repeat=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the timings are consistent, this should hopefully imply that no other processes are interfering with the execution time of your function. This is not a fool-proof solution, there are alternative methods for timing CPU time which would be more accurate, however this is generally good enough to understand how well our code is running.\n",
    "\n",
    "According to the Python documentation the most interesting value of those returned is the minimum. This provides a bound on how fast your machine can run the function that you have provided. Calculating the mean and standard deviation may be misleading if other processes are interfering with your timing accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timing functions with variable input sizes ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have only considered examples with a fixed input to our function, the value 10. It is obviously much more interesting if we can adjust the input value and store any relevant data relating to that specific input. Let us consider the example below where we use a for loop to determine the value of the variable `x` and we provide that as an input to our function for timing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let the input size start at 100, and step up in increments of 100.\n",
    "for x in range (100,1100,100):\n",
    "    y = timeit.timeit('f(x)', globals=globals(), number=1000)\n",
    "    print(\"x =\",x, \", y =\",y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to interpret this data we must pay attention to the fact that we ran our function 1000 times for each input value. Therefore if we want to know how long a single execution of our function takes for a given input we must divide the runtime by the number of repeated experiments, as we can see in the code below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 1000\n",
    "for x in range (100,1100,100):\n",
    "    y = timeit.timeit('f(x)', globals=globals(), number=z)\n",
    "    print(\"x =\",x, \", y =\",y, \", Average =\", y/z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we want to present this data nicely we could store the output in either a Python list or dictionary or even a NumPy ndarray and, as we will in the next topic, we could then use this data with matplotlib to draw some useful graphs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on Complexity ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This content may not make much sense until you have seen some basic complexity theory. This will be covered in both Computational Thinking and Algorithms and Data Structures in the second half of first term. You may want to leave this final section for now if you are unaware of Big-O notation, and revisit this later in the term. You can however move on and complete Notebooks 6.3, 6.4 and 6.5 without this content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point it is also possible to use this data as a proxy for the complexity of the implementation of an algorithm. You can time your implementation across a range of input sizes and investigate how the runtime changes with the input size. For example, if your runtime data shows a clear doubling when the size of the input doubles it suggests that your implementation has linear complexity, $O(n)$. Similarly if the runtime data shows a quadrupling pattern when the input size is doubled your implementation likely has quadratic complexity, $O(n^2)$. If you are aware of the complexity of the algorithm that you have tried to implement, this data can provide a sanity check on whether you have implemented your algorithm reasonably efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at our data, we should see this rough doubling of the runtime when we double the input size, suggesting our function has linear complexity, so is $O(n)$. This seems to make sense, we have a single for loop `for i in range (1,x)` where the range scales linearly with the input `x`, and the code inside the loop is a single operation with runtime that appears independent of the value of `x`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must be careful however, these runtimes are very small and therefore prone to error. We would want to use larger inputs with much larger runtimes to have greater confidence in identifying patterns in the data. The example below will take a couple of minutes to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = 20\n",
    "for x in range (1000000,11000000,1000000):\n",
    "    y = timeit.timeit('f(x)', globals=globals(), number=z)\n",
    "    print(\"x =\",x, \", y =\",y, \", Average =\", y/z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that the linear pattern is not quite as clear. The likely reason is that our assumption the line of code inside the for loop `x += x % 991` is independent of `x` may not be quite true. In fact, most modulo algorithms have complexity $O((log(n))^2)$, so the time required to calculate the modulo will grow with larger values of `x`. This suggests our algorithm probably has complexity of $O(n*(log(n))^2)$, so scales slightly worse than linear. \n",
    "\n",
    "This may be even more obvious if we use a while loop instead, and double the input size on every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 200000\n",
    "z = 20\n",
    "\n",
    "while (x<20000000):\n",
    "    y = timeit.timeit('f(x)', globals=globals(), number=z)\n",
    "    print(\"x =\",x, \", y =\",y, \", Average =\", y/z)\n",
    "    x = 2*x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just remember that generally we would not use timing data to make a guess at the complexity of a particular algorithm. However, it can prove a useful sanity check to ensure that your implementation of an algorithm scales as you would expect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
